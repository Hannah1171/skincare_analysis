{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "431e901f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import matplotlib.dates as mdates\n",
    "import locale\n",
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "from collections import Counter\n",
    "from nltk.util import ngrams\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67661e1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and prepare data\n",
    "df = pd.read_csv(\"../data/raw_data/posts_transcripts_raw.csv\")\n",
    "\n",
    "# Remove posts with less than views\n",
    "df = df[df[\"playCount\"] > 50].copy()\n",
    "\n",
    "df[\"createTimeISO\"] = pd.to_datetime(df[\"createTimeISO\"]).dt.tz_localize(None)\n",
    "\n",
    "# Add week column\n",
    "df[\"week\"] = df[\"createTimeISO\"].dt.to_period(\"W\").dt.start_time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b82395b",
   "metadata": {},
   "source": [
    "Engagement per skincare influencer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "216a9231",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate engagement\n",
    "df[\"engagement\"] = df[\"diggCount\"] + df[\"commentCount\"] + df[\"shareCount\"]\n",
    "\n",
    "# Set up interactive widgets (standardized date range: 6 months)\n",
    "max_date = df[\"createTimeISO\"].max().date()\n",
    "six_months_ago = max_date - timedelta(days=180)\n",
    "\n",
    "start_date = widgets.DatePicker(description='Start Date', value=six_months_ago)\n",
    "end_date = widgets.DatePicker(description='End Date', value=max_date)\n",
    "min_posts_slider = widgets.IntSlider(value=3, min=1, max=20, step=1, description='Min Posts')\n",
    "\n",
    "# Define interactive update function\n",
    "def update_plot(start, end, min_posts):\n",
    "    if start is None or end is None:\n",
    "        print(\"Please select both start and end dates.\")\n",
    "        return\n",
    "\n",
    "    start = pd.to_datetime(start)\n",
    "    end = pd.to_datetime(end)\n",
    "\n",
    "    if start > end:\n",
    "        print(\"Start date must be before end date.\")\n",
    "        return\n",
    "\n",
    "    # Filter data by date range\n",
    "    mask = (df[\"createTimeISO\"] >= start) & (df[\"createTimeISO\"] <= end)\n",
    "    filtered_df = df.loc[mask].copy()\n",
    "\n",
    "    if filtered_df.empty:\n",
    "        print(\"No data available for the selected date range.\")\n",
    "        return\n",
    "\n",
    "    # Group by influencer\n",
    "    grouped = (\n",
    "        filtered_df.groupby(\"author_nickName\")\n",
    "        .agg({\n",
    "            \"engagement\": \"sum\",\n",
    "            \"playCount\": \"sum\",\n",
    "            \"author_fans\": \"first\",\n",
    "            \"id\": \"count\"\n",
    "        })\n",
    "        .rename(columns={\"id\": \"num_posts\"})\n",
    "        .reset_index()\n",
    "    )\n",
    "\n",
    "    # Filter by minimum number of posts\n",
    "    grouped = grouped[grouped[\"num_posts\"] >= min_posts]\n",
    "\n",
    "    if grouped.empty:\n",
    "        print(f\"No influencers with at least {min_posts} posts in this period.\")\n",
    "        return\n",
    "\n",
    "    # Sort and select top 10\n",
    "    top = grouped.sort_values(by=\"engagement\", ascending=False).head(10)\n",
    "\n",
    "    # Plot\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.barh(top[\"author_nickName\"], top[\"engagement\"])\n",
    "    plt.xlabel(\"Total Engagement\")\n",
    "    plt.ylabel(\"Influencer\")\n",
    "    plt.title(f\"Top 10 Influencers by Engagement\\n({start.date()} to {end.date()}, Min Posts: {min_posts})\")\n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Display interactive widgets\n",
    "widgets.interact(update_plot, start=start_date, end=end_date, min_posts=min_posts_slider);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9da73ed3",
   "metadata": {},
   "source": [
    "Spam phrases, viral memes phrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "502d5dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure all necessary columns are included from the start\n",
    "comments_df = df[df[\"text_comment\"].notna()][[\"text_comment\", \"author_nickName\", \"createTimeISO\"]].copy()\n",
    "\n",
    "# Basic text cleaning: lowercase and strip whitespace\n",
    "comments_df[\"text_comment_clean\"] = comments_df[\"text_comment\"].str.strip().str.lower()\n",
    "\n",
    "# Remove exact duplicate comments\n",
    "comments_df = comments_df.drop_duplicates(subset=[\"text_comment_clean\"])\n",
    "\n",
    "# Define known spam/meme phrases to filter out\n",
    "spam_phrases = [\n",
    "    \"speed made you famous\",\n",
    "    \"amy made speed\",\n",
    "    \"speed speed\",\n",
    "    \"famous speed made\",\n",
    "    \"made speed famous\",\n",
    "    \"speed made\",\n",
    "    \"speed\"\n",
    "]\n",
    "spam_pattern = \"|\".join(re.escape(p) for p in spam_phrases)\n",
    "\n",
    "# Exclude comments that match any of the spam patterns\n",
    "filtered_comments_df = comments_df[~comments_df[\"text_comment_clean\"].str.contains(spam_pattern)]\n",
    "\n",
    "# Optionally: filter out comments that contain 'speed' more than once\n",
    "filtered_comments_df[\"speed_count\"] = filtered_comments_df[\"text_comment_clean\"].str.count(r\"\\bspeed\\b\")\n",
    "filtered_comments_df = filtered_comments_df[filtered_comments_df[\"speed_count\"] <= 1]\n",
    "\n",
    "# Clean up: remove the helper column\n",
    "filtered_comments_df = filtered_comments_df.drop(columns=[\"speed_count\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94663464",
   "metadata": {},
   "source": [
    "Common phrases in comments per influencer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c27d3045",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text input for influencer name\n",
    "influencer_input = widgets.Text(\n",
    "    description=\"Influencer:\",\n",
    "    placeholder=\"Enter name, e.g. amyflamy\"\n",
    ")\n",
    "\n",
    "# Date pickers\n",
    "today = df[\"createTimeISO\"].max().date()\n",
    "six_months_ago = today - timedelta(days=180)\n",
    "start_ngram = widgets.DatePicker(description=\"Start Date\", value=six_months_ago)\n",
    "end_ngram = widgets.DatePicker(description=\"End Date\", value=today)\n",
    "\n",
    "# Function for dynamic bigram/trigram output\n",
    "def show_ngrams_manual(influencer, start, end):\n",
    "    clear_output(wait=True)\n",
    "\n",
    "    if not influencer or start is None or end is None:\n",
    "        print(\"Please enter an influencer name and valid dates.\")\n",
    "        return\n",
    "\n",
    "    # Filter comments\n",
    "    start = pd.to_datetime(start)\n",
    "    end = pd.to_datetime(end)\n",
    "\n",
    "    df_filtered = filtered_comments_df[\n",
    "        (filtered_comments_df[\"author_nickName\"] == influencer) &\n",
    "        (filtered_comments_df[\"createTimeISO\"] >= start) &\n",
    "        (filtered_comments_df[\"createTimeISO\"] <= end)\n",
    "    ]\n",
    "\n",
    "    if df_filtered.empty:\n",
    "        print(f\"No comments found for '{influencer}' in selected time range.\")\n",
    "        return\n",
    "\n",
    "    # Tokenize and clean\n",
    "    all_text = \" \".join(df_filtered[\"text_comment\"].dropna())\n",
    "    tokens = [\n",
    "        word for word in word_tokenize(all_text.lower())\n",
    "        if re.match(r'^[a-z]{3,}$', word) and word not in combined_stopwords\n",
    "    ]\n",
    "\n",
    "    bigrams = list(ngrams(tokens, 2))\n",
    "    trigrams = list(ngrams(tokens, 3))\n",
    "\n",
    "    bigram_freq = Counter(bigrams).most_common(20)\n",
    "    trigram_freq = Counter(trigrams).most_common(20)\n",
    "\n",
    "    # Output\n",
    "    print(f\"Top 20 Bigrams for '{influencer}' ({start.date()} to {end.date()}):\")\n",
    "    for bg in bigram_freq:\n",
    "        print(\"  \", \" \".join(bg[0]), \"-\", bg[1])\n",
    "\n",
    "    print(f\"\\nTop 20 Trigrams for '{influencer}':\")\n",
    "    for tg in trigram_freq:\n",
    "        print(\"  \", \" \".join(tg[0]), \"-\", tg[1])\n",
    "\n",
    "# Create interactive output\n",
    "out = widgets.interactive_output(\n",
    "    show_ngrams_manual,\n",
    "    {'influencer': influencer_input, 'start': start_ngram, 'end': end_ngram}\n",
    ")\n",
    "\n",
    "# Pack widgets in Layout\n",
    "ui = widgets.VBox([influencer_input, start_ngram, end_ngram])\n",
    "\n",
    "# Display UI and Output\n",
    "display(ui, out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82be7c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose influencer\n",
    "influencer_name = \"amyflamy\"\n",
    "\n",
    "# Filter cleaned, spam-free comments from the selected influencer\n",
    "influencer_comments = filtered_comments_df[filtered_comments_df[\"author_nickName\"] == influencer_name]\n",
    "\n",
    "# Combine all comments into a single string\n",
    "all_text = \" \".join(influencer_comments[\"text_comment\"].dropna())\n",
    "\n",
    "# Tokenize and filter tokens using combined stopwords\n",
    "tokens = [\n",
    "    word for word in word_tokenize(all_text.lower())\n",
    "    if re.match(r'^[a-z]{3,}$', word) and word not in combined_stopwords\n",
    "]\n",
    "\n",
    "# Create bigrams and trigrams\n",
    "bigrams = list(ngrams(tokens, 2))\n",
    "trigrams = list(ngrams(tokens, 3))\n",
    "\n",
    "# Count most common ones\n",
    "bigram_freq = Counter(bigrams).most_common(20)\n",
    "trigram_freq = Counter(trigrams).most_common(20)\n",
    "\n",
    "# Display results\n",
    "print(\"Top 20 Bigrams:\")\n",
    "for bg in bigram_freq:\n",
    "    print(\" \".join(bg[0]), \"-\", bg[1])\n",
    "\n",
    "print(\"\\nTop 20 Trigrams:\")\n",
    "for tg in trigram_freq:\n",
    "    print(\" \".join(tg[0]), \"-\", tg[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "skincare-analysis-pFfgqJ8c-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
