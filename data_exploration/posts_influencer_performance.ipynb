{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "431e901f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to C:\\Users\\Surface/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\Surface/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Surface/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "C:\\Users\\Surface\\AppData\\Local\\Temp\\ipykernel_19632\\2420426634.py:31: DtypeWarning: Columns (12,34) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(\"../data/comments_post.csv\")\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import matplotlib.dates as mdates\n",
    "import locale\n",
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "from collections import Counter\n",
    "from nltk.util import ngrams\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "from transformers import pipeline\n",
    "\n",
    "\n",
    "# Download NLTK Ressourcen\n",
    "nltk.download(\"punkt\")\n",
    "nltk.download('punkt_tab')\n",
    "nltk.download(\"stopwords\")\n",
    "\n",
    "# Set matplotlib to use English for dates\n",
    "try:\n",
    "    locale.setlocale(locale.LC_TIME, 'en_US.UTF-8')\n",
    "except locale.Error:\n",
    "    locale.setlocale(locale.LC_TIME, 'C')\n",
    "\n",
    "# Load and prepare data\n",
    "df = pd.read_csv(\"../data/comments_post.csv\")\n",
    "\n",
    "# Basic cleaning\n",
    "df = df[df[\"text_comment\"].notna() & (df[\"playCount\"] > 0)].copy()\n",
    "df[\"text_comment\"] = df[\"text_comment\"].astype(str).str.lower()\n",
    "\n",
    "# Parse datetime and remove timezone (tz-naive)\n",
    "df[\"createTimeISO\"] = pd.to_datetime(df[\"createTimeISO\"]).dt.tz_localize(None)\n",
    "\n",
    "# Add week column\n",
    "df[\"week\"] = df[\"createTimeISO\"].dt.to_period(\"W\").dt.start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dd82902a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define standard and custom stopwords\n",
    "standard_stopwords = set(stopwords.words(\"german\")) | set(stopwords.words(\"english\"))\n",
    "custom_stopwords = {\n",
    "    \"i\", \"you\", \"it\", \"me\", \"this\", \"that\", \"we\", \"she\", \"he\", \"they\", \"u\", \"ur\",\n",
    "    \"my\", \"your\", \"yours\", \"ours\", \"their\", \"its\", \"use\", \"like\", \"get\", \"need\", \n",
    "    \"please\", \"one\", \"would\", \"watch\", \"want\", \"que\", \"tbh\", \"idk\", \"fr\", \n",
    "    \"literally\", \"actually\", \"honestly\", \"kinda\", \"thing\", \"stuff\", \"good\", \"bad\", \n",
    "    \"ðŸ˜­\", \"ðŸ˜‚\", \"âœ¨\", \"ðŸ’€\", \"ðŸ’…\", \"ðŸ¥°\", \"ðŸ˜©\", \"ðŸ˜…\", \"ðŸ¥º\", \"ðŸ˜³\"\n",
    "}\n",
    "\n",
    "# Unigram-specific stopwords (standard + custom)\n",
    "combined_stopwords = standard_stopwords | custom_stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b82395b",
   "metadata": {},
   "source": [
    "Engagement per skincare influencer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "216a9231",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d98bfcd28b04f81ba85c9875664fa29",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(DatePicker(value=datetime.date(2024, 9, 30), description='Start Date', step=1), DatePickâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Calculate engagement\n",
    "df[\"engagement\"] = df[\"diggCount\"] + df[\"commentCount\"] + df[\"shareCount\"]\n",
    "\n",
    "# Set up interactive widgets (standardized date range 6 months)\n",
    "max_date = df[\"createTimeISO\"].max().date()\n",
    "six_months_ago = max_date - timedelta(days=180)\n",
    "\n",
    "start_date = widgets.DatePicker(description='Start Date', value=six_months_ago)\n",
    "end_date = widgets.DatePicker(description='End Date', value=max_date)\n",
    "min_posts_slider = widgets.IntSlider(value=3, min=1, max=20, step=1, description='Min Posts')\n",
    "\n",
    "# Define interactive update function\n",
    "def update_plot(start, end, min_posts):\n",
    "    if start is None or end is None:\n",
    "        print(\"Please select both start and end date.\")\n",
    "        return\n",
    "\n",
    "    start = pd.to_datetime(start)\n",
    "    end = pd.to_datetime(end)\n",
    "\n",
    "    # Filter data by date range\n",
    "    mask = (df[\"createTimeISO\"] >= start) & (df[\"createTimeISO\"] <= end)\n",
    "    filtered_df = df[mask].copy()\n",
    "\n",
    "    if filtered_df.empty:\n",
    "        print(\"No data available for selected date range.\")\n",
    "        return\n",
    "\n",
    "    # Group by influencer\n",
    "    grouped = filtered_df.groupby(\"author_nickName\").agg({\n",
    "        \"engagement\": \"sum\",\n",
    "        \"playCount\": \"sum\",\n",
    "        \"author_fans\": \"first\",\n",
    "        \"id\": \"count\"\n",
    "    }).rename(columns={\"id\": \"num_posts\"}).reset_index()\n",
    "\n",
    "    # Filter by minimum number of posts\n",
    "    grouped = grouped[grouped[\"num_posts\"] >= min_posts]\n",
    "\n",
    "    if grouped.empty:\n",
    "        print(f\"No influencers with at least {min_posts} posts in this period.\")\n",
    "        return\n",
    "\n",
    "    # Sort and select top 10\n",
    "    top = grouped.sort_values(by=\"engagement\", ascending=False).head(10)\n",
    "\n",
    "    # Plot\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.barh(top[\"author_nickName\"], top[\"engagement\"])\n",
    "    plt.xlabel(\"Total Engagement\")\n",
    "    plt.ylabel(\"Influencer\")\n",
    "    plt.title(f\"Top 10 Influencers by Engagement\\n({start.date()} to {end.date()}, Min Posts: {min_posts})\")\n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Display interactive widgets\n",
    "widgets.interact(update_plot, start=start_date, end=end_date, min_posts=min_posts_slider);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9da73ed3",
   "metadata": {},
   "source": [
    "Spam phrases, viral memes phrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "502d5dc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Surface\\AppData\\Local\\Temp\\ipykernel_19632\\3602684941.py:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_comments_df[\"speed_count\"] = filtered_comments_df[\"text_comment_clean\"].str.count(r\"\\bspeed\\b\")\n"
     ]
    }
   ],
   "source": [
    "# Ensure all necessary columns are included from the start\n",
    "comments_df = df[df[\"text_comment\"].notna()][[\"text_comment\", \"author_nickName\", \"createTimeISO\"]].copy()\n",
    "\n",
    "# Basic text cleaning: lowercase and strip whitespace\n",
    "comments_df[\"text_comment_clean\"] = comments_df[\"text_comment\"].str.strip().str.lower()\n",
    "\n",
    "# Remove exact duplicate comments\n",
    "comments_df = comments_df.drop_duplicates(subset=[\"text_comment_clean\"])\n",
    "\n",
    "# Define known spam/meme phrases to filter out\n",
    "spam_phrases = [\n",
    "    \"speed made you famous\",\n",
    "    \"amy made speed\",\n",
    "    \"speed speed\",\n",
    "    \"famous speed made\",\n",
    "    \"made speed famous\",\n",
    "    \"speed made\",\n",
    "    \"speed\"\n",
    "]\n",
    "spam_pattern = \"|\".join(re.escape(p) for p in spam_phrases)\n",
    "\n",
    "# Exclude comments that match any of the spam patterns\n",
    "filtered_comments_df = comments_df[~comments_df[\"text_comment_clean\"].str.contains(spam_pattern)]\n",
    "\n",
    "# Optionally: filter out comments that contain 'speed' more than once\n",
    "filtered_comments_df[\"speed_count\"] = filtered_comments_df[\"text_comment_clean\"].str.count(r\"\\bspeed\\b\")\n",
    "filtered_comments_df = filtered_comments_df[filtered_comments_df[\"speed_count\"] <= 1]\n",
    "\n",
    "# Clean up: remove the helper column\n",
    "filtered_comments_df = filtered_comments_df.drop(columns=[\"speed_count\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94663464",
   "metadata": {},
   "source": [
    "Common phrases in comments per influencer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c27d3045",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4da29e92a48408db735a4f412d22aa8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Text(value='', description='Influencer:', placeholder='Enter name, e.g. amyflamy'), DatePicker(â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62dc1dd084be4a9b800834b12c66ef82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Text input for influencer name\n",
    "influencer_input = widgets.Text(\n",
    "    description=\"Influencer:\",\n",
    "    placeholder=\"Enter name, e.g. amyflamy\"\n",
    ")\n",
    "\n",
    "# Date pickers\n",
    "today = df[\"createTimeISO\"].max().date()\n",
    "six_months_ago = today - timedelta(days=180)\n",
    "start_ngram = widgets.DatePicker(description=\"Start Date\", value=six_months_ago)\n",
    "end_ngram = widgets.DatePicker(description=\"End Date\", value=today)\n",
    "\n",
    "# Function for dynamic bigram/trigram output\n",
    "def show_ngrams_manual(influencer, start, end):\n",
    "    clear_output(wait=True)\n",
    "\n",
    "    if not influencer or start is None or end is None:\n",
    "        print(\"Please enter an influencer name and valid dates.\")\n",
    "        return\n",
    "\n",
    "    # Filter comments\n",
    "    start = pd.to_datetime(start)\n",
    "    end = pd.to_datetime(end)\n",
    "\n",
    "    df_filtered = filtered_comments_df[\n",
    "        (filtered_comments_df[\"author_nickName\"] == influencer) &\n",
    "        (filtered_comments_df[\"createTimeISO\"] >= start) &\n",
    "        (filtered_comments_df[\"createTimeISO\"] <= end)\n",
    "    ]\n",
    "\n",
    "    if df_filtered.empty:\n",
    "        print(f\"No comments found for '{influencer}' in selected time range.\")\n",
    "        return\n",
    "\n",
    "    # Tokenize and clean\n",
    "    all_text = \" \".join(df_filtered[\"text_comment\"].dropna())\n",
    "    tokens = [\n",
    "        word for word in word_tokenize(all_text.lower())\n",
    "        if re.match(r'^[a-z]{3,}$', word) and word not in combined_stopwords\n",
    "    ]\n",
    "\n",
    "    bigrams = list(ngrams(tokens, 2))\n",
    "    trigrams = list(ngrams(tokens, 3))\n",
    "\n",
    "    bigram_freq = Counter(bigrams).most_common(20)\n",
    "    trigram_freq = Counter(trigrams).most_common(20)\n",
    "\n",
    "    # Output\n",
    "    print(f\"Top 20 Bigrams for '{influencer}' ({start.date()} to {end.date()}):\")\n",
    "    for bg in bigram_freq:\n",
    "        print(\"  \", \" \".join(bg[0]), \"-\", bg[1])\n",
    "\n",
    "    print(f\"\\nTop 20 Trigrams for '{influencer}':\")\n",
    "    for tg in trigram_freq:\n",
    "        print(\"  \", \" \".join(tg[0]), \"-\", tg[1])\n",
    "\n",
    "# Create interactive output\n",
    "out = widgets.interactive_output(\n",
    "    show_ngrams_manual,\n",
    "    {'influencer': influencer_input, 'start': start_ngram, 'end': end_ngram}\n",
    ")\n",
    "\n",
    "# Pack widgets in Layout\n",
    "ui = widgets.VBox([influencer_input, start_ngram, end_ngram])\n",
    "\n",
    "# Display UI and Output\n",
    "display(ui, out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "82be7c1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 20 Bigrams:\n",
      "korean skincare - 11\n",
      "without makeup - 9\n",
      "cleansing oil - 7\n",
      "song kang - 6\n",
      "skin care - 5\n",
      "take care - 5\n",
      "skincare routine - 4\n",
      "beautiful without - 4\n",
      "dry skin - 4\n",
      "white fungus - 4\n",
      "hair routine - 3\n",
      "much better - 3\n",
      "love videos - 3\n",
      "amy pretty - 3\n",
      "got girl - 3\n",
      "relief cream - 3\n",
      "anyone grwm - 3\n",
      "oily skin - 3\n",
      "skincare products - 3\n",
      "clear skin - 3\n",
      "\n",
      "Top 20 Trigrams:\n",
      "beautiful without makeup - 4\n",
      "hair perfume oil - 3\n",
      "winter shade summer - 2\n",
      "korean skincare really - 2\n",
      "love korean skincare - 2\n",
      "vaseline clog pores - 2\n",
      "content creator easy - 2\n",
      "creator easy job - 2\n",
      "oil instead cleansing - 2\n",
      "instead cleansing oil - 2\n",
      "love white fungus - 2\n",
      "white fungus mushrooms - 2\n",
      "cant believe got - 1\n",
      "believe got meet - 1\n",
      "got meet heize - 1\n",
      "meet heize see - 1\n",
      "heize see cried - 1\n",
      "see cried girl - 1\n",
      "cried girl hair - 1\n",
      "girl hair routine - 1\n"
     ]
    }
   ],
   "source": [
    "# Choose influencer\n",
    "influencer_name = \"amyflamy\"\n",
    "\n",
    "# Filter cleaned, spam-free comments from the selected influencer\n",
    "influencer_comments = filtered_comments_df[filtered_comments_df[\"author_nickName\"] == influencer_name]\n",
    "\n",
    "# Combine all comments into a single string\n",
    "all_text = \" \".join(influencer_comments[\"text_comment\"].dropna())\n",
    "\n",
    "# Tokenize and filter tokens using combined stopwords\n",
    "tokens = [\n",
    "    word for word in word_tokenize(all_text.lower())\n",
    "    if re.match(r'^[a-z]{3,}$', word) and word not in combined_stopwords\n",
    "]\n",
    "\n",
    "# Create bigrams and trigrams\n",
    "bigrams = list(ngrams(tokens, 2))\n",
    "trigrams = list(ngrams(tokens, 3))\n",
    "\n",
    "# Count most common ones\n",
    "bigram_freq = Counter(bigrams).most_common(20)\n",
    "trigram_freq = Counter(trigrams).most_common(20)\n",
    "\n",
    "# Display results\n",
    "print(\"Top 20 Bigrams:\")\n",
    "for bg in bigram_freq:\n",
    "    print(\" \".join(bg[0]), \"-\", bg[1])\n",
    "\n",
    "print(\"\\nTop 20 Trigrams:\")\n",
    "for tg in trigram_freq:\n",
    "    print(\" \".join(tg[0]), \"-\", tg[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "skincare-analysis-6rggZTBS-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
