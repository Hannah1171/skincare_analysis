{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "week  Rank          Hashtag  Post Count Avg. Engagement Trendline  \\\n",
      "91       1         skincare        3061            -48%         ðŸ“‰   \n",
      "97       2  skincareroutine        1788            -38%         ðŸ“‰   \n",
      "53       3       hautpflege        1766            -89%         ðŸ“‰   \n",
      "34       4              fyp        1352           +323%         ðŸ“ˆ   \n",
      "61       5   koreanskincare         833           +171%         ðŸ“ˆ   \n",
      "44       6           glowup         560          +2028%         ðŸ“ˆ   \n",
      "101      7     skincaretips         554           +585%         ðŸ“ˆ   \n",
      "57       8          kbeauty         537           +381%         ðŸ“ˆ   \n",
      "83       9         selfcare         522            -48%         ðŸ“‰   \n",
      "9       10           beauty         454            -86%         ðŸ“‰   \n",
      "\n",
      "week       Top Creator(s)  \n",
      "91                  manel  \n",
      "97               amyflamy  \n",
      "53                    Sri  \n",
      "34                heylina  \n",
      "61                heylina  \n",
      "44    Masculine Vouge USA  \n",
      "101              amyflamy  \n",
      "57        Skincarebyshade  \n",
      "83               tholhahs  \n",
      "9                 jess à±¨à§Ž  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5k/b8_r8jw502n4zztm42zd76m80000gn/T/ipykernel_38325/1469635468.py:8: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
      "  df['week'] = df['createTimeISO'].dt.to_period('W').dt.start_time\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# STEP 1: Load your dataset\n",
    "df = pd.read_csv(\"/Users/ritushetkar/env_capstone/data/hashtags_posts.csv\", parse_dates=['createTimeISO'])\n",
    "\n",
    "# STEP 2: Preprocessing\n",
    "df['week'] = df['createTimeISO'].dt.to_period('W').dt.start_time\n",
    "df['engagement'] = df[['diggCount', 'shareCount', 'commentCount']].sum(axis=1)\n",
    "\n",
    "# STEP 3: Explode hashtags (if multiple hashtags per post)\n",
    "df['hashtag_name'] = df['hashtag_name'].fillna('')\n",
    "df['hashtag_list'] = df['hashtag_name'].apply(lambda x: x.split(',') if ',' in x else [x])\n",
    "df_exploded = df.explode('hashtag_list')\n",
    "df_exploded['hashtag_list'] = df_exploded['hashtag_list'].str.strip().str.lower()\n",
    "df_exploded = df_exploded[df_exploded['hashtag_list'] != '']  # remove empty tags\n",
    "\n",
    "# STEP 4: Weekly hashtag stats\n",
    "weekly_stats = (\n",
    "    df_exploded.groupby(['hashtag_list', 'week'])\n",
    "    .agg(post_count=('post_id', 'count'),\n",
    "         avg_engagement=('engagement', 'mean'))\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# STEP 5: Compute % change in engagement for last 2 weeks\n",
    "latest_weeks = sorted(weekly_stats['week'].unique())[-2:]\n",
    "\n",
    "latest_df = weekly_stats[weekly_stats['week'].isin(latest_weeks)]\n",
    "pivot = latest_df.pivot(index='hashtag_list', columns='week', values='avg_engagement').dropna()\n",
    "\n",
    "pivot['engagement_change'] = ((pivot[latest_weeks[1]] - pivot[latest_weeks[0]]) / pivot[latest_weeks[0]]) * 100\n",
    "\n",
    "# STEP 6: Top creators per hashtag\n",
    "top_creators = (\n",
    "    df_exploded.groupby(['hashtag_list', 'author_nickName'])\n",
    "    .agg(total_engagement=('engagement', 'sum'))\n",
    "    .reset_index()\n",
    "    .sort_values(['hashtag_list', 'total_engagement'], ascending=[True, False])\n",
    "    .drop_duplicates('hashtag_list')\n",
    "    .set_index('hashtag_list')['author_nickName']\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "# STEP 7: Final leaderboard\n",
    "hashtag_counts = df_exploded['hashtag_list'].value_counts()\n",
    "leaderboard = pivot.copy()\n",
    "leaderboard['post_count'] = hashtag_counts\n",
    "\n",
    "# ðŸ”½ FILTER HERE\n",
    "MIN_POST_THRESHOLD = 50\n",
    "leaderboard = leaderboard[leaderboard['post_count'] >= MIN_POST_THRESHOLD]\n",
    "\n",
    "leaderboard['trend'] = np.where(leaderboard['engagement_change'] > 0, 'ðŸ“ˆ', 'ðŸ“‰')\n",
    "leaderboard['engagement_change_fmt'] = leaderboard['engagement_change'].apply(lambda x: f\"{x:+.0f}%\")\n",
    "leaderboard['top_creator'] = leaderboard.index.map(top_creators)\n",
    "\n",
    "\n",
    "\n",
    "leaderboard['trend'] = np.where(leaderboard['engagement_change'] > 0, 'ðŸ“ˆ', 'ðŸ“‰')\n",
    "leaderboard['engagement_change_fmt'] = leaderboard['engagement_change'].apply(lambda x: f\"{x:+.0f}%\")\n",
    "leaderboard['top_creator'] = leaderboard.index.map(top_creators)\n",
    "\n",
    "# STEP 8: Sort and display\n",
    "final = leaderboard.reset_index().rename(columns={\n",
    "    'hashtag_list': 'Hashtag',\n",
    "    'post_count': 'Post Count',\n",
    "    'engagement_change_fmt': 'Avg. Engagement',\n",
    "    'trend': 'Trendline',\n",
    "    'top_creator': 'Top Creator(s)'\n",
    "})[['Hashtag', 'Post Count', 'Avg. Engagement', 'Trendline', 'Top Creator(s)']]\n",
    "\n",
    "final['Rank'] = final['Post Count'].rank(method='first', ascending=False).astype(int)\n",
    "final = final.sort_values('Rank')\n",
    "\n",
    "# Reorder columns\n",
    "final = final[['Rank', 'Hashtag', 'Post Count', 'Avg. Engagement', 'Trendline', 'Top Creator(s)']]\n",
    "\n",
    "# Display\n",
    "print(final.head(10))  # or st.dataframe(final) in Streamlit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5k/b8_r8jw502n4zztm42zd76m80000gn/T/ipykernel_38325/2350887214.py:17: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
      "  df['week'] = df['createTimeISO'].dt.to_period('W').dt.start_time\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e6e9085691d4456bedbc2812b181495",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1835 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# === PART 1: Predict Trending Hashtags === #\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(\"/Users/ritushetkar/env_capstone/data/hashtags_posts.csv\", parse_dates=['createTimeISO'])\n",
    "\n",
    "# Preprocess time and hashtags\n",
    "df['week'] = df['createTimeISO'].dt.to_period('W').dt.start_time\n",
    "df['engagement'] = df[['diggCount', 'shareCount', 'commentCount']].sum(axis=1)\n",
    "df['hashtag_name'] = df['hashtag_name'].fillna('')\n",
    "df['hashtag_list'] = df['hashtag_name'].apply(lambda x: x.split(',') if ',' in x else [x])\n",
    "df_exploded = df.explode('hashtag_list')\n",
    "df_exploded['hashtag_list'] = df_exploded['hashtag_list'].str.strip().str.lower()\n",
    "df_exploded = df_exploded[df_exploded['hashtag_list'] != '']\n",
    "\n",
    "# Weekly aggregation\n",
    "weekly = (\n",
    "    df_exploded.groupby(['hashtag_list', 'week'])\n",
    "    .agg(post_count=('post_id', 'count'),\n",
    "         avg_engagement=('engagement', 'mean'),\n",
    "         sponsored_ratio=('isSponsored', 'mean'))\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# Sort weeks and calculate growth\n",
    "weekly = weekly.sort_values(['hashtag_list', 'week'])\n",
    "weekly['prev_post_count'] = weekly.groupby('hashtag_list')['post_count'].shift(1)\n",
    "weekly['growth_rate'] = (weekly['post_count'] - weekly['prev_post_count']) / (weekly['prev_post_count'] + 1e-6)\n",
    "weekly['is_trending'] = (weekly['growth_rate'] > 0.5).astype(int)\n",
    "weekly = weekly.dropna()\n",
    "\n",
    "# Encode categorical\n",
    "le = LabelEncoder()\n",
    "weekly['hashtag_encoded'] = le.fit_transform(weekly['hashtag_list'])\n",
    "\n",
    "# Features and labels\n",
    "X = weekly[['hashtag_encoded', 'post_count', 'avg_engagement', 'growth_rate', 'sponsored_ratio']]\n",
    "y = weekly['is_trending']\n",
    "\n",
    "# Train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train classifier\n",
    "clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Report\n",
    "part1_report = classification_report(y_test, y_pred, output_dict=True)\n",
    "\n",
    "\n",
    "# === PART 2: Skincare Hashtag Classifier === #\n",
    "\n",
    "# Create simple labeled dataset (manually labeled or based on rules)\n",
    "def label_skincare_related(tag):\n",
    "    skincare_keywords = ['skin', 'spf', 'acne', 'moisturizer', 'sunscreen', 'kbeauty', 'glow']\n",
    "    return int(any(kw in tag.lower() for kw in skincare_keywords))\n",
    "\n",
    "df_tags = df_exploded[['hashtag_list', 'text']].dropna().drop_duplicates()\n",
    "df_tags['label'] = df_tags['hashtag_list'].apply(label_skincare_related)\n",
    "\n",
    "# Use sentence-transformers to embed text context (hashtag + caption)\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "df_tags['combined_text'] = df_tags['hashtag_list'] + \" \" + df_tags['text']\n",
    "embeddings = model.encode(df_tags['combined_text'].tolist(), show_progress_bar=True)\n",
    "\n",
    "# Train classifier\n",
    "X_embed = np.array(embeddings)\n",
    "y_embed = df_tags['label'].values\n",
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(X_embed, y_embed, test_size=0.2, random_state=42)\n",
    "\n",
    "clf2 = LogisticRegression(max_iter=1000)\n",
    "clf2.fit(X_train2, y_train2)\n",
    "y_pred2 = clf2.predict(X_test2)\n",
    "\n",
    "# Report\n",
    "part2_report = classification_report(y_test2, y_pred2, output_dict=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Trending Hashtag Prediction Report ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      2434\n",
      "           1       1.00      1.00      1.00       626\n",
      "\n",
      "    accuracy                           1.00      3060\n",
      "   macro avg       1.00      1.00      1.00      3060\n",
      "weighted avg       1.00      1.00      1.00      3060\n",
      "\n",
      "\n",
      "=== Skincare Hashtag Classifier Report ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.93      0.90      8462\n",
      "           1       0.78      0.67      0.72      3282\n",
      "\n",
      "    accuracy                           0.86     11744\n",
      "   macro avg       0.83      0.80      0.81     11744\n",
      "weighted avg       0.85      0.86      0.85     11744\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Print Trending Hashtag Classifier Results\n",
    "print(\"=== Trending Hashtag Prediction Report ===\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Print Skincare Classifier Results\n",
    "print(\"\\n=== Skincare Hashtag Classifier Report ===\")\n",
    "print(classification_report(y_test2, y_pred2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Trending Hashtag Report ===\n",
      "              precision  recall  f1-score  support\n",
      "0                   1.0     1.0       1.0   2434.0\n",
      "1                   1.0     1.0       1.0    626.0\n",
      "accuracy            1.0     1.0       1.0      1.0\n",
      "macro avg           1.0     1.0       1.0   3060.0\n",
      "weighted avg        1.0     1.0       1.0   3060.0\n",
      "\n",
      "=== Skincare Hashtag Report ===\n",
      "              precision    recall  f1-score       support\n",
      "0              0.879056  0.928504  0.903103   8462.000000\n",
      "1              0.784391  0.670628  0.723062   3282.000000\n",
      "accuracy       0.856437  0.856437  0.856437      0.856437\n",
      "macro avg      0.831723  0.799566  0.813083  11744.000000\n",
      "weighted avg   0.852600  0.856437  0.852789  11744.000000\n"
     ]
    }
   ],
   "source": [
    "# Convert the dictionary report into a DataFrame\n",
    "df_trending_report = pd.DataFrame(part1_report).transpose()\n",
    "df_skincare_report = pd.DataFrame(part2_report).transpose()\n",
    "\n",
    "# Show top rows\n",
    "print(\"=== Trending Hashtag Report ===\")\n",
    "print(df_trending_report.head())\n",
    "\n",
    "print(\"\\n=== Skincare Hashtag Report ===\")\n",
    "print(df_skincare_report.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Hashtags Predicted as Trending ===\n",
      "          hashtag  actual  predicted\n",
      "20065         pov       1          1\n",
      "11609       hauls       1          1\n",
      "11144       haare       1          1\n",
      "27413  velvetskin       1          1\n",
      "9043      fypdong       1          1\n",
      "\n",
      "=== Hashtags Predicted as Not Trending ===\n",
      "               hashtag  actual  predicted\n",
      "9128          fypviral       0          0\n",
      "7007   eatyourskincare       0          0\n",
      "12898          hygiene       0          0\n",
      "16814            model       0          0\n",
      "12715   hyaluronicacid       0          0\n"
     ]
    }
   ],
   "source": [
    "# Add model predictions back to the test set\n",
    "X_test_with_preds = X_test.copy()\n",
    "X_test_with_preds['actual'] = y_test\n",
    "X_test_with_preds['predicted'] = y_pred\n",
    "\n",
    "# Map encoded hashtags back to original names\n",
    "X_test_with_preds['hashtag'] = le.inverse_transform(X_test_with_preds['hashtag_encoded'])\n",
    "\n",
    "# Show trending predictions\n",
    "print(\"=== Hashtags Predicted as Trending ===\")\n",
    "print(X_test_with_preds[X_test_with_preds['predicted'] == 1][['hashtag', 'actual', 'predicted']].head())\n",
    "\n",
    "print(\"\\n=== Hashtags Predicted as Not Trending ===\")\n",
    "print(X_test_with_preds[X_test_with_preds['predicted'] == 0][['hashtag', 'actual', 'predicted']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Hashtags Predicted as Skincare ===\n",
      "          hashtag_list                                               text  \\\n",
      "66117         skincare  not once but TWICEðŸ˜­ðŸ˜­ god forbid a girl just wa...   \n",
      "35618     harmancheema  Skincare tips I wish I knew sooner #skin #clea...   \n",
      "40066          kbeauty  Honestly, the Mandelic Acid Gentle Exfoliating...   \n",
      "11035  skincareroutine  Summer skin loading ðŸŒ´ðŸŒ´#skincare #beauty #skinc...   \n",
      "44434      glowingskin  RIP to my eye, stay tunedðŸ’€ but anyway Do my ni...   \n",
      "\n",
      "       actual  \n",
      "66117       1  \n",
      "35618       0  \n",
      "40066       1  \n",
      "11035       1  \n",
      "44434       1  \n",
      "\n",
      "=== Hashtags Predicted as Non-Skincare ===\n",
      "            hashtag_list                                               text  \\\n",
      "59673  porenverfeinerung  âœ¨ FUTURACONTOUR â€“ Die innovative Unterspritzun...   \n",
      "36430         hautpflege  Ich suche 10 tÃ¼rkisch sprechenden Frauen, die ...   \n",
      "29848  hautpflegeroutine  NatÃ¼rlich, sanft und effektiv â€“ die perfekte P...   \n",
      "67319            goviral  Lieblingstag der Woche!ðŸ˜‹ðŸ©· #fyp #foryou #fÃ¼rdic...   \n",
      "49560                 vj  Korean skincare at Etos! ðŸ§´ðŸŒ¸ #koreanskincare #e...   \n",
      "\n",
      "       actual  \n",
      "59673       0  \n",
      "36430       0  \n",
      "29848       0  \n",
      "67319       0  \n",
      "49560       0  \n"
     ]
    }
   ],
   "source": [
    "# Add predictions to the test set\n",
    "# Create indices to keep track of original rows\n",
    "indices = np.arange(len(df_tags))\n",
    "\n",
    "# Split embeddings and indices together\n",
    "X_train2, X_test2, y_train2, y_test2, idx_train, idx_test = train_test_split(\n",
    "    X_embed, y_embed, indices, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Use idx_test to select the right rows from df_tags\n",
    "df_test = df_tags.iloc[idx_test].copy()\n",
    "df_test['actual'] = y_test2\n",
    "df_test['predicted'] = y_pred2\n",
    "\n",
    "df_test['actual'] = y_test2\n",
    "df_test['predicted'] = y_pred2\n",
    "\n",
    "print(\"=== Hashtags Predicted as Skincare ===\")\n",
    "print(df_test[df_test['predicted'] == 1][['hashtag_list', 'text', 'actual']].head())\n",
    "\n",
    "print(\"\\n=== Hashtags Predicted as Non-Skincare ===\")\n",
    "print(df_test[df_test['predicted'] == 0][['hashtag_list', 'text', 'actual']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
